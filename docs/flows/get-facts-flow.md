# Get Facts Flow

The **Get Facts Flow** describes how the AI Assistant (LLM), through OpenProfile, retrieves **userâ€‘approved facts** from connected Fact Pods to deliver more accurate, contextâ€‘aware responses.

This flow happens **after the user has already enabled** one or more Fact Pods (see â€œEnable Fact Pod Flowâ€).

## Sequence Overview

```mermaid
---
config:
  look: neo
  theme: redux
---
sequenceDiagram
    actor User
    participant LLM as AI Assistant
    participant Gateway as Gateway<br>[OpenProfile]
    participant FactPod as Site.com<br>[OpenProfile Fact Pod]

    %% Step 1 - User request
    User->>LLM: "Recommend a body lotion for my skin"

    %% Step 2 - Fetch available Fact Pods
    LLM->>Gateway: (1) getAvailableFactPods()
    Gateway-->>LLM: (2) List of Fact Pods + Categories

    %% Step 3 - Select relevant categories and fetch facts
    LLM->>LLM: Select relevant categories
    LLM->>Gateway: (3) getFacts(selected categories)

    %% Step 4 - Query Fact Pods for data
    Gateway->>FactPod: (4) Request facts (e.g. purchase history, preferences)
    FactPod-->>Gateway: (5) Return facts
    Gateway-->>LLM: (6) Provide available facts

    %% Step 5 - Generate answer
    LLM->>LLM: Generate personalized recommendation
    LLM-->>User: Return answer tailored to skin type & preferences
```

## Step-by-Step Description

### **1. User Makes a Request**
- The user asks the LLM for help, e.g.,
  > "Recommend a body lotion for my skin"
- The AI Assistant may need additional **user-specific context** (such as skin type, past purchases, or brand preferences) to answer meaningfully.

### **2. Get List of Enabled Fact Pods**
- **LLM â†’ Gateway (1)** â€” The LLM asks the Gateway for a list of Fact Pods the user has already connected and authorized.
- **Gateway â†’ LLM (2)** â€” Returns:
    - Fact Pod names and descriptions
    - Available fact categories (e.g., *Purchase History*, *Wishlist*, *Profile Data*)
    - Metadata describing what each fact category represents

**Why important:** This step lets the LLM know what **context sources** are available without directly accessing sensitive data yet.

### **3. Select Relevant Categories & Request Facts**
- **LLM â†’ LLM:** The AI internally decides what fact categories could improve the answer (e.g., *skincare purchase history*, *skin condition preferences*).
- **LLM â†’ Gateway (3)** â€” Requests facts for the selected categories.
- The Gateway handles secure retrieval â€” the LLM never directly connects to Fact Pods.

### **4. Gateway Retrieves Facts from Fact Pods**
- **Gateway â†’ FactPod (4)** â€” The Gateway sends a facts request to the relevant Fact Pod(s).  
  Only categories the user has already authorized are included.
- **FactPod â†’ Gateway (5)** â€” The Fact Pod returns the facts. Example:
    - Previous purchases containing aloe vera
    - Recorded preference: "Sensitive skin"
    - Wishlist skin products

Tokens obtained during the **Enable Fact Pod Flow** are used here to authenticate securely.

### **5. Gateway Delivers Facts to LLM**
- **Gateway â†’ LLM (6)** â€” Sends back the retrieved facts in a structured format.
- No raw API secrets or tokens are exposed to the LLM.

### **6. LLM Generates Personalized Answer**
- Using the provided facts, the LLM tailors its response:
    - Recognizes userâ€™s purchase history suggests **fragrance-free** products
    - Aligns brand recommendations to wishlist
    - Filters for sensitive skin products
- **LLM â†’ User:** Returns a highly personalized recommendation.

## ğŸ” Key Privacy & Trust Principles
- **User consent is respected** â€” only authorized categories are accessed.
- **Secure token handling** â€” LLM never holds tokens; the Gateway manages authentication.
- **Minimum necessary data** â€” only facts relevant to the request are fetched.
- **No data persistence in LLM** (beyond the current conversation context).

---
